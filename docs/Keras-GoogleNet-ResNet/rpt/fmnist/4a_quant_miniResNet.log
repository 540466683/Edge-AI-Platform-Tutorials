  0% |                                                                        |  5% |###                                                                     | 10% |#######                                                                 | 15% |##########                                                              | 20% |##############                                                          | 25% |##################                                                      | 30% |#####################                                                   | 35% |#########################                                               | 40% |############################                                            | 45% |################################                                        | 50% |####################################                                    | 55% |#######################################                                 | 60% |###########################################                             | 65% |##############################################                          | 70% |##################################################                      | 75% |######################################################                  | 80% |#########################################################               | 85% |#############################################################           | 90% |################################################################        | 95% |####################################################################    |100% |########################################################################|[DEPLOY WARNING] Batchnorm Node (batch_normalization_1/FusedBatchNorm_1/add + batch_normalization_1/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_1/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_5/FusedBatchNorm_1/add + batch_normalization_5/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_5/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_8/FusedBatchNorm_1/add + batch_normalization_8/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_8/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_11/FusedBatchNorm_1/add + batch_normalization_11/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_11/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_14/FusedBatchNorm_1/add + batch_normalization_14/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_14/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_17/FusedBatchNorm_1/add + batch_normalization_17/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_17/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_20/FusedBatchNorm_1/add + batch_normalization_20/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_20/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_23/FusedBatchNorm_1/add + batch_normalization_23/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_23/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_26/FusedBatchNorm_1/add + batch_normalization_26/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_26/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_29/FusedBatchNorm_1/add + batch_normalization_29/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_29/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_32/FusedBatchNorm_1/add + batch_normalization_32/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_32/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_35/FusedBatchNorm_1/add + batch_normalization_35/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_35/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_38/FusedBatchNorm_1/add + batch_normalization_38/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_38/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_41/FusedBatchNorm_1/add + batch_normalization_41/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_41/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_44/FusedBatchNorm_1/add + batch_normalization_44/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_44/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_47/FusedBatchNorm_1/add + batch_normalization_47/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_47/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_50/FusedBatchNorm_1/add + batch_normalization_50/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_50/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_53/FusedBatchNorm_1/add + batch_normalization_53/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_53/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_56/FusedBatchNorm_1/add + batch_normalization_56/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_56/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_59/FusedBatchNorm_1/add + batch_normalization_59/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_59/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_62/FusedBatchNorm_1/add + batch_normalization_62/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_62/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_65/FusedBatchNorm_1/add + batch_normalization_65/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_65/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_68/FusedBatchNorm_1/add + batch_normalization_68/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_68/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_71/FusedBatchNorm_1/add + batch_normalization_71/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_71/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_74/FusedBatchNorm_1/add + batch_normalization_74/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_74/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_77/FusedBatchNorm_1/add + batch_normalization_77/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_77/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_80/FusedBatchNorm_1/add + batch_normalization_80/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_80/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.
[DEPLOY WARNING] Batchnorm Node (batch_normalization_83/FusedBatchNorm_1/add + batch_normalization_83/FusedBatchNorm_1/mul) is not folded. It will be converted to a Scale node (batch_normalization_83/FusedBatchNorm_1/add) to deploy on DPU. This may cause accuracy decrease and error for DPU compiler.

script running on folder  /home/danieleb/ML/TF/KERAS-CUSTOM-CNN/code
CALIB DIR  /home/danieleb/ML/TF/KERAS-CUSTOM-CNN/code/../dataset/fashion-mnist/calib/
INFO: Checking Float Graph...
INFO: Float Graph Check Done.
INFO: Calibrating for 20 iterations...
INFO: Calibration Done.
INFO: Generating Deploy Model...
INFO: Deploy Model Generated.
********************* Quantization Summary *********************      
INFO: Output:       
  quantize_eval_model: ../quantized_results/fmnist/miniResNet/quantize_eval_model.pb       
  deploy_model: ../quantized_results/fmnist/miniResNet/deploy_model.pb
